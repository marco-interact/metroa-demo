# Deployment Commands - Frontend & Backend

## ‚úÖ Code Pushed Successfully!
All changes have been pushed to: `https://github.com/marco-interact/metroa-demo.git`

---

## üé® Frontend Deployment (Vercel)

### Option 1: Auto-Deploy (Recommended)
Vercel will automatically deploy from GitHub when you push to `main` branch.

**Check deployment status:**
```bash
# Open Vercel dashboard
open https://vercel.com/marco-interact/metroa-demo
```

If you need to manually redeploy:

### Option 2: Manual Deploy via CLI
```bash
# Install Vercel CLI (if not installed)
npm install -g vercel

# Login to Vercel
vercel login

# Deploy to production
cd /Users/marco.aurelio/Desktop/metroa-demo
vercel --prod
```

### Option 3: Deploy via Vercel Dashboard
1. Go to https://vercel.com/marco-interact
2. Find your project: `metroa-demo` 
3. Click "Deployments"
4. Click "Redeploy" on latest deployment
5. Select "Production" branch

**Frontend URL**: Will be provided after deployment completes

---

## üñ•Ô∏è Backend Deployment (RunPod RTX 4090)

### Step 1: Connect to Your RunPod
```bash
# SSH into your RunPod (replace with your pod details)
ssh root@<your-pod-ip> -p <ssh-port>

# Or use RunPod web terminal
```

### Step 2: Navigate to Project
```bash
cd /workspace/metroa-demo

# If project doesn't exist, clone it:
# git clone https://github.com/marco-interact/metroa-demo.git metroa-demo
# cd metroa-demo
```

### Step 3: Pull Latest Changes
```bash
# Pull the new optimizations
git pull origin main

# Should show:
# - build-colmap-gpu-fixed.sh updated
# - colmap_processor.py updated
# - RTX4090 guides added
```

### Step 4: Rebuild COLMAP with RTX 4090 Optimizations
```bash
# This rebuilds COLMAP with all optimizations
bash build-colmap-gpu-fixed.sh

# Expected output:
# ‚úÖ COLMAP built with:
#    - Fast math optimizations
#    - Native architecture flags
#    - CUDA O3 optimizations
#    - Compute capability 8.9 (RTX 4090)
#
# Time: ~10-15 minutes
```

**While it builds, you can:**
- ‚òï Grab a coffee
- üìä Monitor: `watch -n 1 nvidia-smi`
- üìù Read: `cat RTX4090_OPTIMIZATION_GUIDE.md`

### Step 5: Install Python Dependencies (if needed)
```bash
# Upgrade pip
pip install --upgrade pip

# Install requirements
pip install -r requirements.txt

# Key packages:
# - fastapi
# - uvicorn
# - python-multipart
# - Pillow
```

### Step 6: Setup Environment Variables
```bash
# Create/update .env file
cat > .env << 'EOF'
# Backend Configuration
PORT=8000
HOST=0.0.0.0

# Database
DATABASE_URL=sqlite:///./data/metroa.db

# COLMAP
COLMAP_BINARY=/usr/local/bin/colmap
COLMAP_GPU=true

# File Storage
UPLOAD_DIR=/workspace/metroa-demo/data/uploads
CACHE_DIR=/workspace/metroa-demo/data/cache
RESULTS_DIR=/workspace/metroa-demo/data/results

# Processing
DEFAULT_QUALITY=high
MAX_FRAMES=100

# Frontend URL (update with your Vercel URL)
FRONTEND_URL=https://metroa-demo.vercel.app
CORS_ORIGINS=https://metroa-demo.vercel.app,http://localhost:3000

# Optional: Email notifications
# SMTP_HOST=smtp.gmail.com
# SMTP_PORT=587
# NOTIFICATION_EMAIL=your-email@example.com
EOF

# Set permissions
chmod 600 .env
```

### Step 7: Create Data Directories
```bash
# Ensure data directories exist
mkdir -p data/{uploads,cache,results}
mkdir -p data/cache/{jobs,thumbnails}

# Set permissions
chmod -R 755 data/
```

### Step 8: Test COLMAP Installation
```bash
# Verify COLMAP is working
colmap -h | head -20

# Check CUDA linkage
ldd $(which colmap) | grep cuda

# Should show:
# libcudart.so.12
# libcublas.so.12
# etc.

# Test GPU access
nvidia-smi

# Should show RTX 4090 with 24GB VRAM
```

### Step 9: Start Backend Server
```bash
# Option A: Direct Python (for testing)
python main.py

# Option B: With uvicorn (recommended for production)
uvicorn main:app --host 0.0.0.0 --port 8000 --reload

# Option C: Background process with logs
nohup python main.py > logs/backend.log 2>&1 &

# Option D: Using screen (survives disconnection)
screen -S metroa-backend
python main.py
# Press Ctrl+A, then D to detach
# Reattach: screen -r metroa-backend
```

### Step 10: Verify Backend is Running
```bash
# Check if server is listening
curl http://localhost:8000/api/health

# Should return:
# {"status":"ok","version":"1.0","colmap":"available","gpu":"RTX 4090"}

# Check from outside
curl http://<your-pod-ip>:8000/api/health
```

### Step 11: Configure Firewall/Ports
```bash
# Ensure port 8000 is exposed in RunPod settings
# Go to RunPod dashboard ‚Üí Your Pod ‚Üí Ports
# Expose port 8000 (HTTP)

# Get your public endpoint
echo "Backend URL: http://<your-pod-ip>:8000"
```

### Step 12: Update Frontend Environment
Back on your local machine:

```bash
cd /Users/marco.aurelio/Desktop/metroa-demo

# Update .env.production with your RunPod backend URL
cat > .env.production << EOF
NEXT_PUBLIC_API_URL=http://<your-pod-ip>:8000
NEXT_PUBLIC_API_BASE_URL=http://<your-pod-ip>:8000/api
EOF

# Push this change
git add .env.production
git commit -m "Update backend URL for RunPod deployment"
git push origin main

# Vercel will auto-redeploy with new backend URL
```

---

## üß™ Testing the Deployment

### Test 1: Frontend Health Check
```bash
# Open in browser
open https://metroa-demo.vercel.app

# Should show the dashboard
```

### Test 2: Backend Health Check
```bash
curl http://<your-pod-ip>:8000/api/health

# Expected response:
{
  "status": "ok",
  "version": "1.0",
  "colmap": "available",
  "colmap_version": "3.10",
  "gpu": "NVIDIA RTX 4090",
  "gpu_available": true,
  "optimizations": "RTX4090 Enhanced"
}
```

### Test 3: Point Selection in 3D Viewer
1. Go to a scan's 3D viewer page
2. Click Ruler icon (Measurement Tool)
3. Click on model ‚Üí Should see **Point A (Green)** üü¢
4. Click again ‚Üí Should see **Point B (Blue)** üîµ
5. Both points should have:
   - Large glowing spheres
   - Animated rings
   - Clear labels
   - Status indicators in UI

### Test 4: Run a Test Reconstruction
```bash
# On RunPod backend, tail the logs
tail -f logs/backend.log

# From frontend:
# 1. Create a new project
# 2. Upload a video
# 3. Start processing with quality="high"
# 4. Watch GPU utilization: watch -n 1 nvidia-smi

# Expected processing time for 60 frames:
# - Feature extraction: ~2-3 minutes (with GPU)
# - Feature matching: ~1-2 minutes (with GPU)
# - Sparse reconstruction: ~3-5 minutes
# - Dense reconstruction: ~10-15 minutes (with GPU)
# Total: ~20-25 minutes for HIGH quality with 6M+ points
```

### Test 5: Verify Optimizations Are Active
```bash
# Check logs for optimization indicators
grep -i "RTX\|GPU\|features\|samples" logs/backend.log

# Should see:
# "Extracting features with quality=high using GPU"
# "max_num_features: 65536"
# "num_samples: 50"
# "cache_size: 64"
# "window_radius: 11"
```

---

## üìä Monitoring

### GPU Monitoring (RunPod)
```bash
# Real-time GPU stats
watch -n 1 nvidia-smi

# GPU utilization history
nvidia-smi dmon -s u -c 100

# Check GPU memory
nvidia-smi --query-gpu=memory.used,memory.total --format=csv
```

### Backend Logs
```bash
# Follow logs
tail -f logs/backend.log

# Search for errors
grep -i error logs/backend.log

# Check recent processing jobs
grep -i "processing complete" logs/backend.log | tail -5
```

### Vercel Logs
```bash
# Via CLI
vercel logs

# Or visit dashboard:
# https://vercel.com/marco-interact/metroa-demo/logs
```

---

## üîß Troubleshooting

### Issue: Frontend can't connect to backend
**Solution**:
```bash
# Check CORS settings in main.py
# Ensure your Vercel URL is in allowed origins

# Check firewall on RunPod
# Ensure port 8000 is exposed

# Test direct connection
curl -v http://<your-pod-ip>:8000/api/health
```

### Issue: COLMAP not using GPU
**Solution**:
```bash
# Verify CUDA linkage
ldd $(which colmap) | grep cuda

# If no CUDA libraries, rebuild:
bash build-colmap-gpu-fixed.sh

# Check GPU availability
nvidia-smi
```

### Issue: Out of memory during reconstruction
**Solution**:
```bash
# Use medium quality instead of high
# Or reduce max_frames in processing

# Check available memory
nvidia-smi --query-gpu=memory.free --format=csv
```

### Issue: Vercel deployment failed
**Solution**:
```bash
# Check build logs
vercel logs --follow

# Common fixes:
# - npm install (update dependencies)
# - Check for TypeScript errors
# - Verify environment variables

# Force redeploy
vercel --prod --force
```

---

## üìù Quick Reference

### Backend URLs
```
Health Check: http://<pod-ip>:8000/api/health
Projects API: http://<pod-ip>:8000/api/projects
Scans API:    http://<pod-ip>:8000/api/projects/{id}/scans
```

### Frontend URL
```
Production: https://metroa-demo.vercel.app
Preview:    https://metroa-demo-<hash>.vercel.app
```

### Key Files
```
Backend Config:  /workspace/metroa-demo/.env
Backend Logs:    /workspace/metroa-demo/logs/
Frontend Config: /Users/marco.aurelio/Desktop/metroa-demo/.env.production
COLMAP Binary:   /usr/local/bin/colmap
```

---

## üéâ Deployment Complete!

You should now have:
- ‚úÖ Frontend deployed on Vercel
- ‚úÖ Backend running on RunPod with RTX 4090
- ‚úÖ COLMAP optimized for 2-4x denser point clouds
- ‚úÖ Point selection working with A/B nomenclature
- ‚úÖ 40-60% faster processing times

**Next Steps**:
1. Test point selection in 3D viewer
2. Run a test reconstruction to verify optimizations
3. Monitor first few jobs to ensure stability
4. Enjoy your ultra-dense point clouds! üöÄ

---

**Need Help?**
- üìñ Full technical details: `RTX4090_OPTIMIZATION_GUIDE.md`
- ‚ö° Quick start: `QUICKSTART_RTX4090.md`
- üìù Cleanup plan: `CLEANUP_PLAN.md`

**Last Updated**: November 12, 2025

